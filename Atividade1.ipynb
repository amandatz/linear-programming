{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amandatz/linear-programming/blob/main/Atividade1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkGVnRe9CPdx"
      },
      "source": [
        "# Atividade 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thdM6TiJWo3c"
      },
      "source": [
        "Amanda Topanotti Zanette (22100776)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRXSFVsDWq4e"
      },
      "source": [
        "**Importações e funções auxiliares**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HWjqEDuVIgTF"
      },
      "outputs": [],
      "source": [
        "using LinearAlgebra, Printf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esse trecho de código é usado apenas para garantir a repetibilidade dos números aleatórios gerados."
      ],
      "metadata": {
        "id": "7xszQjRRAATk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "using Random\n",
        "Random.seed!(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayAFiLALAAyM",
        "outputId": "71b51052-a410-44e7-b728-0141a32ae4c0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TaskLocalRNG()"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iC9tSXZLCTw9"
      },
      "source": [
        "## Questão 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gradiente com backtracking**"
      ],
      "metadata": {
        "id": "gpNzvk14M1lp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "function steepest_descent_backtracking(fun, x0; sigma=1e-4, rho=0.5, max_iter=2000, tol=1e-6)\n",
        "  x = copy(x0)\n",
        "\n",
        "  for k = 0:max_iter-1\n",
        "    f, g, _ = fun(x)\n",
        "    gnorm = norm(g)\n",
        "\n",
        "    if gnorm <= tol\n",
        "      return x, k, gnorm\n",
        "    end\n",
        "\n",
        "    # backtracking\n",
        "    t = 1.0\n",
        "    xn = x - t*g\n",
        "    fn, _, _= fun(xn)\n",
        "\n",
        "    while fn > f - sigma*t*gnorm^2\n",
        "      t *= rho\n",
        "      xn = x - t*g\n",
        "      fn, _, _ = fun(xn)\n",
        "    end\n",
        "\n",
        "    x = xn\n",
        "  end\n",
        "\n",
        "  _, g, _ = fun(x)\n",
        "  gnorm = norm(g)\n",
        "  return x, max_iter, gnorm\n",
        "end\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdjzmeIAGMf-",
        "outputId": "cd439bf9-a946-4cac-d7bd-4154cdfd275b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "steepest_descent_backtracking (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Newton com backtracking**"
      ],
      "metadata": {
        "id": "HndsAOTKM3zz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O método de Newton é dado por\n",
        "$$\n",
        "  x_{k+1} = x_k - \\alpha_k H(x_k)^{-1} \\nabla f(x_k)\n",
        "$$\n",
        "em que\n",
        "- $\\nabla f(x_k)$: gradiente de f;\n",
        "- $H(x_k)$: matriz hessiana de f;\n",
        "- $\\alpha_k$: tamanho do passo."
      ],
      "metadata": {
        "id": "lSkkMof1ov6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "function newton_backtracking(fun, x0; sigma=1e-4, rho=0.5, max_iter=2000, tol=1e-6, fallback=nothing)\n",
        "  x = copy(x0)\n",
        "\n",
        "  for k = 0:max_iter-1\n",
        "    f, g, H = fun(x)\n",
        "    gnorm = norm(g)\n",
        "\n",
        "    if gnorm <= tol\n",
        "      return x, k, gnorm\n",
        "    end\n",
        "\n",
        "    p = -(H \\ g)\n",
        "\n",
        "    # se não for direção de descida, usa fallback se existir\n",
        "    if fallback != nothing && g' * p >= 0\n",
        "      p = fallback(g, H)\n",
        "    end\n",
        "\n",
        "    # backtracking\n",
        "    t = 1.0\n",
        "    xn = x + t*p\n",
        "    fn, _, _ = fun(xn)\n",
        "\n",
        "    while fn > f + sigma*t*(g' * p)\n",
        "        t *= rho\n",
        "        xn = x + t*p\n",
        "        fn, _, _ = fun(xn)\n",
        "    end\n",
        "\n",
        "    x = xn\n",
        "  end\n",
        "\n",
        "  f, g, H = fun(x)\n",
        "  return x, max_iter, norm(g)\n",
        "end"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZ5v9Z5ONXUu",
        "outputId": "12a5ec26-c3ed-4223-c75f-16d57901549b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "newton_backtracking (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnekAseLCVy8"
      },
      "source": [
        "## Questão 2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Considere a função de Rosenbrock"
      ],
      "metadata": {
        "id": "3xS6VTM-Bn0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "function rosenb(x)\n",
        "  a = 1.0\n",
        "  b = 10.0\n",
        "\n",
        "  f = (a - x[1])^2 + b*(x[2] - x[1]^2)^2\n",
        "\n",
        "  grad_f = [ -2*(a - x[1]) + 2*b*(x[2] - x[1]^2)*(-2*x[1]),\n",
        "        2*b*(x[2] - x[1]^2)]\n",
        "\n",
        "  hess_f = [\n",
        "        2 - 4*b*(x[2] - x[1]^2) + 8*b*x[1]^2   -4*b*x[1];\n",
        "        -4*b*x[1]                               2*b\n",
        "  ]\n",
        "\n",
        "  return f, grad_f, hess_f\n",
        "end"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clYbT8rbBw1D",
        "outputId": "0c4a07fb-f14b-44c8-c094-ffee39d5301a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "rosenb (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparemos ambos os métodos anteriores considerando os pontos iniciais $x_0 = (1.01, 1.01)$ e $x_1 = (-1.0, 1.2)$"
      ],
      "metadata": {
        "id": "Mx_AfghMCt4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x0 = [1.01, 1.01]\n",
        "\n",
        "x, max_iter_sd, gnorm_sd = steepest_descent_backtracking(rosenb, x0)\n",
        "@printf(\"Gradiente:\\n  Número de iterações: %d\\n  Gradiente final: %.6e\\n  Ponto final: [%.6f, %.6f]\\n\\n\",\n",
        "        max_iter_sd, gnorm_sd, x[1], x[2])\n",
        "\n",
        "x, max_iter_n, gnorm_n = newton_backtracking(rosenb, x0)\n",
        "@printf(\"Newton:\\n  Número de iterações: %d\\n  Gradiente final (norma): %.6e\\n  Ponto final: [%.6f, %.6f]\\n\\n\",\n",
        "        max_iter_n, gnorm_n, x[1], x[2])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "em0_EC6vDKNG",
        "outputId": "c3a37906-d551-446d-aefa-ee776784faee"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradiente:\n",
            "  Número de iterações: 1027\n",
            "  Gradiente final: 9.818612e-07\n",
            "  Ponto final: [1.000001, 1.000002]\n",
            "\n",
            "Newton:\n",
            "  Número de iterações: 3\n",
            "  Gradiente final (norma): 4.895830e-10\n",
            "  Ponto final: [1.000000, 1.000000]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para $x_0 = (1.01, 1.01)$ próximo do mínimo $x^* = (1,1)$, o método de Newton converge quadraticamente, resultando em apenas 3 iterações, enquanto o método do gradiente precisou de 1027 iterações. Além disso, o método de Newton foi bem mais preciso quando comparado ao método do gradiente."
      ],
      "metadata": {
        "id": "BUSTmUFzEIbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = [-1.0, 1.2]\n",
        "\n",
        "x, max_iter_sd, gnorm_sd = steepest_descent_backtracking(rosenb, x1)\n",
        "@printf(\"Gradiente:\\n  Número de iterações: %d\\n  Gradiente final: %.6e\\n  Ponto final: [%.6f, %.6f]\\n\\n\",\n",
        "        max_iter_sd, gnorm_sd, x[1], x[2])\n",
        "\n",
        "x, max_iter_n, gnorm_n = newton_backtracking(rosenb, x1, max_iter=5000)\n",
        "@printf(\"Newton:\\n  Número de iterações: %d\\n  Gradiente final (norma): %.6e\\n  Ponto final: [%.6f, %.6f]\\n\\n\",\n",
        "        max_iter_n, gnorm_n, x[1], x[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ek9SUpKDS6I",
        "outputId": "33546e68-3316-4936-a414-f64c275a193d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradiente:\n",
            "  Número de iterações: 1184\n",
            "  Gradiente final: 9.714477e-07\n",
            "  Ponto final: [0.999999, 0.999998]\n",
            "\n",
            "Newton:\n",
            "  Número de iterações: 5000\n",
            "  Gradiente final (norma): 5.656854e+00\n",
            "  Ponto final: [-1.000000, 1.200000]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para $x_0 = (-1.0, 1.2)$, mais distante, Newton falha em convergir (5000 iterações) porque $H(x)$ longe do mínimo não é positiva definida, enquanto o gradiente ainda converge (1184 iterações).\n"
      ],
      "metadata": {
        "id": "_31aotrtRis2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observe que, para a função de Rosenbrock\n",
        "\n",
        "$$\n",
        "  f(x_1, x_2) = (x_1 - 1)^2 + 10 (x_2 - x_1^2)^2,\n",
        "$$\n",
        "\n",
        "a Hessiana no ponto $x_0 = (-1, 1.2)$ é\n",
        "\n",
        "$$\n",
        "  H(x) =\n",
        "  \\begin{bmatrix}\n",
        "  74 & 40 \\\\\n",
        "  40 & 20\n",
        "  \\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "e o determinante é\n",
        "\n",
        "$$\n",
        "  \\det(H) = -120 < 0\n",
        "$$\n",
        "\n",
        "ou seja, a Hessiana **não é positiva definida** nesse ponto. Isso explica por que o método de Newton não converge a partir desse ponto inicial.\n"
      ],
      "metadata": {
        "id": "nWhx8UtUEbbx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos ajustar o algoritmo de Newton de modo que, caso a Hessiana não seja positiva definida, o método utilize o gradiente como alternativa."
      ],
      "metadata": {
        "id": "wx89YnSjMK4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gradient_fallback(g, H) = -g / norm(g)  # direção do gradiente normalizada\n",
        "\n",
        "x, max_iter_n, gnorm_n = newton_backtracking(rosenb, x1, max_iter=5000, fallback=gradient_fallback)\n",
        "@printf(\"Newton:\\n  Número de iterações: %d\\n  Gradiente final (norma): %.6e\\n  Ponto final: [%.6f, %.6f]\\n\\n\",\n",
        "        max_iter_n, gnorm_n, x[1], x[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6xQOcQFLIAz",
        "outputId": "b2d5bab8-dde3-4e75-95d2-7fd70f75fae0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fallback: 1\n",
            "Fallback: 2\n",
            "Newton:\n",
            "  Número de iterações: 12\n",
            "  Gradiente final (norma): 8.406475e-08\n",
            "  Ponto final: [1.000000, 1.000000]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzBgumq1CYA2"
      },
      "source": [
        "## Questão 3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "function exact_line_search_quadratic(A, b, x, d)\n",
        "  numerator = dot(b, d) - dot(d, A * x)\n",
        "  denominator = dot(d, A * d)\n",
        "\n",
        "  if denominator <= 0 || abs(denominator) < 1e-14\n",
        "    return 1e-6   # passo mínimo seguro\n",
        "  end\n",
        "  return numerator / denominator\n",
        "end"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAFJt8bFrv1U",
        "outputId": "9ff3957b-53be-4ba5-b1d6-761037f1f8b8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "exact_line_search_quadratic (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "function quadratic(x, A, b)\n",
        "  f = 0.5 * dot(x, A * x) - dot(b, x)\n",
        "  g = A * x - b\n",
        "  H = A\n",
        "  return f, g, H\n",
        "end"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryacwBarqdTh",
        "outputId": "8e1dcf43-31cc-4f2d-8862-d3bdab99ee35"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "quadratic (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "function householder_matrix(n)\n",
        "  u = randn(n)\n",
        "  u /= norm(u)\n",
        "  U = Matrix(I, n, n) - 2.0 * (u * u')\n",
        "  return U\n",
        "end"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usNTyzyP0OEg",
        "outputId": "2a23a1dd-8614-4651-a277-e838b2a82b88"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "householder_matrix (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gradiente com busca linear exata**"
      ],
      "metadata": {
        "id": "hkm5yTJVhOv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "function steepest_descent_exact(A, b, x0; max_iter=2000, tol=1e-6)\n",
        "  x = copy(x0)\n",
        "\n",
        "  for k = 0:max_iter-1\n",
        "    f, g, _ = quadratic(x, A, b)\n",
        "\n",
        "    gnorm = norm(g)\n",
        "    if gnorm <= tol\n",
        "      return x, k, gnorm\n",
        "    end\n",
        "\n",
        "    d = -g\n",
        "\n",
        "    # Busca linear exata\n",
        "    alpha = exact_line_search_quadratic(A, b, x, d)\n",
        "\n",
        "    x = x + alpha * d\n",
        "  end\n",
        "\n",
        "  f, g, _ = quadratic(x, A, b)\n",
        "  gnorm = norm(g)\n",
        "  return x, max_iter, gnorm\n",
        "end"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSWeM9ScsFPN",
        "outputId": "f2838143-7612-4f6e-e515-0e9b80c5cd58"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "steepest_descent_exact (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Newton com busca linear exata**"
      ],
      "metadata": {
        "id": "vV_BWIVFhRvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "function newton_exact(A, b, x0; max_iter=2000, tol=1e-6)\n",
        "  x = copy(x0)\n",
        "\n",
        "  for k = 0:max_iter-1\n",
        "    f, g, H = quadratic(x, A, b)\n",
        "\n",
        "    gnorm = norm(g)\n",
        "    if gnorm <= tol\n",
        "      return x, k, gnorm\n",
        "    end\n",
        "\n",
        "    p = - H \\ g\n",
        "\n",
        "    # passo exato\n",
        "    alpha = exact_line_search_quadratic(A, b, x, p)\n",
        "\n",
        "    x = x + alpha * p\n",
        "  end\n",
        "\n",
        "  f, g, H = quadratic(x, A, b)\n",
        "  return x, max_iter, norm(g)\n",
        "end"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLL9JItHMYah",
        "outputId": "f7432fb2-f76d-464b-d7e0-9ede09adb5a8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "newton_exact (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cria uma instância quadrática $f(x) = \\tfrac{1}{2} x^T A x - b^T x$ de dimensão $n$ com uma distribuição específica de autovalores:  \n",
        "- `:equal`: todos os autovalores iguais (bem condicionada).  \n",
        "- `:two`: apenas dois valores diferentes (condicionamento moderado).  \n",
        "- `:spread`: autovalores variados de 1 até 1000 (mal condicionada)."
      ],
      "metadata": {
        "id": "s1Xx8LPVhsb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "function generate_quadratic_instance(n, case)\n",
        "  U = householder_matrix(n)\n",
        "\n",
        "  eigenvalues = zeros(n)\n",
        "\n",
        "  if case == :equal\n",
        "    eigenvalues .= 1.0\n",
        "  elseif case == :two\n",
        "    eigenvalues[1:div(n,2)] .= 2.0\n",
        "    eigenvalues[div(n,2)+1:end] .= 5.0\n",
        "    shuffle!(eigenvalues)\n",
        "  elseif case == :spread\n",
        "    eigenvalues .= collect(LinRange(1.0, 1000.0, n))\n",
        "    shuffle!(eigenvalues)\n",
        "  else\n",
        "    error(\"unkown case\")\n",
        "  end\n",
        "\n",
        "  Lambda = Diagonal(eigenvalues)\n",
        "  A = U * Lambda * U'\n",
        "  A = 0.5 * (A + A')   # garante simetria\n",
        "\n",
        "  b = randn(n) # mudar, pode usar vetor b igual a 0\n",
        "  x0 = randn(n) # mudar, pode usar x0 (diferente de 0), talvez vetor igual a 1\n",
        "\n",
        "  return A, b, x0, eigenvalues\n",
        "end"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6aRxP-0yTMk",
        "outputId": "dd6c11ed-1679-40ee-bc4f-910c26fe2367"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "generate_quadratic_instance (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neste bloco, aplicamos os métodos de otimização (`steepest_descent_exact` e `newton_exact`) em várias instâncias quadráticas geradas:\n",
        "\n",
        "- `dimensions = [10, 100, 1000]`: diferentes tamanhos da matriz $A$.  \n",
        "- `cases = [:equal, :two, :spread]`: diferentes distribuições de autovalores para testar o condicionamento.\n"
      ],
      "metadata": {
        "id": "yYN8ENPaiIut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dimensions = [10, 100, 1000]\n",
        "cases = [:equal, :two, :spread]\n",
        "\n",
        "for n in dimensions, case in cases\n",
        "    A, b, x0, eigenvalues = generate_quadratic_instance(n, case)\n",
        "\n",
        "    # Gradiente\n",
        "    t_sd = @elapsed x_sd, k_sd, gnorm_sd = steepest_descent_exact(A, b, x0, max_iter=10000)\n",
        "\n",
        "    # Newton\n",
        "    t_newt = @elapsed x_newt, k_newt, gnorm_newt = newton_exact(A, b, x0, max_iter=10000)\n",
        "\n",
        "    println(\"Dimensão: $n, Caso: $case\")\n",
        "    println(\"  Gradiente:\")\n",
        "    println(\"    Iterações: $k_sd\")\n",
        "    println(\"    Tempo: $(round(t_sd, digits=4)) s\")\n",
        "    println(\"  Newton:\")\n",
        "    println(\"    Iterações: $k_newt\")\n",
        "    println(\"    Tempo: $(round(t_newt, digits=4)) s\\n\")\n",
        "end\n",
        "\n",
        "## ADICIONAR AVALIAÇÃO DE FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CYt3iuHMbHo",
        "outputId": "7230d298-110e-4d1b-aed1-40a09e33c33f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensão: 10, Caso: equal\n",
            "  Gradiente:\n",
            "    Iterações: 1\n",
            "    Tempo: 0.2687 s\n",
            "  Newton:\n",
            "    Iterações: 1\n",
            "    Tempo: 0.158 s\n",
            "\n",
            "Dimensão: 10, Caso: two\n",
            "  Gradiente:\n",
            "    Iterações: 11\n",
            "    Tempo: 0.0 s\n",
            "  Newton:\n",
            "    Iterações: 1\n",
            "    Tempo: 0.0 s\n",
            "\n",
            "Dimensão: 10, Caso: spread\n",
            "  Gradiente:\n",
            "    Iterações: 6873\n",
            "    Tempo: 0.0238 s\n",
            "  Newton:\n",
            "    Iterações: 1\n",
            "    Tempo: 0.0 s\n",
            "\n",
            "Dimensão: 100, Caso: equal\n",
            "  Gradiente:\n",
            "    Iterações: 1\n",
            "    Tempo: 0.0 s\n",
            "  Newton:\n",
            "    Iterações: 1\n",
            "    Tempo: 0.0003 s\n",
            "\n",
            "Dimensão: 100, Caso: two\n",
            "  Gradiente:\n",
            "    Iterações: 15\n",
            "    Tempo: 0.0001 s\n",
            "  Newton:\n",
            "    Iterações: 1\n",
            "    Tempo: 0.0001 s\n",
            "\n",
            "Dimensão: 100, Caso: spread\n",
            "  Gradiente:\n",
            "    Iterações: 6579\n",
            "    Tempo: 0.0505 s\n",
            "  Newton:\n",
            "    Iterações: 1\n",
            "    Tempo: 0.0002 s\n",
            "\n",
            "Dimensão: 1000, Caso: equal\n",
            "  Gradiente:\n",
            "    Iterações: 1\n",
            "    Tempo: 0.0027 s\n",
            "  Newton:\n",
            "    Iterações: 1\n",
            "    Tempo: 0.0378 s\n",
            "\n",
            "Dimensão: 1000, Caso: two\n",
            "  Gradiente:\n",
            "    Iterações: 17\n",
            "    Tempo: 0.0247 s\n",
            "  Newton:\n",
            "    Iterações: 1\n",
            "    Tempo: 0.1859 s\n",
            "\n",
            "Dimensão: 1000, Caso: spread\n",
            "  Gradiente:\n",
            "    Iterações: 7453\n",
            "    Tempo: 10.4932 s\n",
            "  Newton:\n",
            "    Iterações: 1\n",
            "    Tempo: 0.0325 s\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observa-se que o método de Newton converge em apenas uma iteração para todos os casos testados, independentemente da dimensão da matriz ou da distribuição dos autovalores. Isso ocorre porque, para uma função quadrática, a direção de Newton aponta exatamente para o mínimo, e o passo exato leva diretamente a ele. O tempo de execução aumenta levemente com a dimensão devido à necessidade de resolver o sistema linear $H p = g$, mas permanece extremamente baixo.\n",
        "\n",
        "Por outro lado, o desempenho do método do gradiente dependente do condicionamento da matriz $A$. Nos casos de autovalores iguais ou com apenas dois distintos, o número de iterações necessárias é relativamente baixo. Entretanto, quando os autovalores estão muito espalhados, o método precisa de mais iterações para convergir. O tempo de processamento cresce significativamente à medida que a dimensão da matriz aumenta."
      ],
      "metadata": {
        "id": "zn1JgXKCjth3"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Julia",
      "name": "julia"
    },
    "language_info": {
      "name": "julia"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}