{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amandatz/linear-programming/blob/main/Atividade1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkGVnRe9CPdx"
      },
      "source": [
        "# Atividade 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thdM6TiJWo3c"
      },
      "source": [
        "Amanda Topanotti Zanette (22100776)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRXSFVsDWq4e"
      },
      "source": [
        "**Importações e funções auxiliares**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HWjqEDuVIgTF"
      },
      "outputs": [],
      "source": [
        "using LinearAlgebra, Printf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esse trecho de código é usado apenas para garantir a repetibilidade dos números aleatórios gerados."
      ],
      "metadata": {
        "id": "7xszQjRRAATk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "using Random\n",
        "Random.seed!(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayAFiLALAAyM",
        "outputId": "c2585e94-0a79-4c9b-d30f-95bfcafe087e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TaskLocalRNG()"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iC9tSXZLCTw9"
      },
      "source": [
        "## Questão 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gradiente com backtracking**"
      ],
      "metadata": {
        "id": "gpNzvk14M1lp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "function steepest_descent_backtracking(fun, x0; sigma=1e-4, rho=0.5, max_iter=2000, tol=1e-6)\n",
        "  x = copy(x0)\n",
        "\n",
        "  for k = 0:max_iter-1\n",
        "    f, g, _ = fun(x)\n",
        "    gnorm = norm(g)\n",
        "\n",
        "    if gnorm <= tol\n",
        "      return x, k, gnorm\n",
        "    end\n",
        "\n",
        "    # backtracking\n",
        "    t = 1.0\n",
        "    xn = x - t*g\n",
        "    fn, _, _= fun(xn)\n",
        "\n",
        "    while fn > f - sigma*t*gnorm^2\n",
        "      t *= rho\n",
        "      xn = x - t*g\n",
        "      fn, _, _ = fun(xn)\n",
        "    end\n",
        "\n",
        "    x = xn\n",
        "  end\n",
        "\n",
        "  _, g, _ = fun(x)\n",
        "  gnorm = norm(g)\n",
        "  return x, max_iter, gnorm\n",
        "end\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdjzmeIAGMf-",
        "outputId": "ac7758f3-eb24-4bfa-dd60-d9cbc830ae31"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "steepest_descent_backtracking (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Newton com backtracking**"
      ],
      "metadata": {
        "id": "HndsAOTKM3zz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O método de Newton é dado por\n",
        "$$\n",
        "  x_{k+1} = x_k - \\alpha_k H(x_k)^{-1} \\nabla f(x_k)\n",
        "$$\n",
        "em que\n",
        "- $\\nabla f(x_k)$: gradiente de f;\n",
        "- $H(x_k)$: matriz hessiana de f;\n",
        "- $\\alpha_k$: tamanho do passo."
      ],
      "metadata": {
        "id": "lSkkMof1ov6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "function newton_backtracking(fun, x0; sigma=1e-4, rho=0.5, max_iter=2000, tol=1e-6)\n",
        "  x = copy(x0)\n",
        "\n",
        "  for k = 0:max_iter-1\n",
        "    f, g, H = fun(x)\n",
        "    gnorm = norm(g)\n",
        "\n",
        "    if gnorm <= tol\n",
        "      return x, k, gnorm\n",
        "    end\n",
        "\n",
        "    p = H \\ g # VER ISSO DAQUI\n",
        "    t = 1.0\n",
        "    xn = x - t*p\n",
        "    fn, _, _= fun(xn)\n",
        "\n",
        "    # backtracking\n",
        "    while fn > f - sigma*t*(g' * p)\n",
        "      t *= rho\n",
        "      xn = x - t*p\n",
        "      fn, _, _ = fun(xn)\n",
        "    end\n",
        "\n",
        "    x = xn\n",
        "  end\n",
        "\n",
        "  f, g, H = fun(x)\n",
        "  return x, max_iter, norm(g)\n",
        "end\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZ5v9Z5ONXUu",
        "outputId": "76c1ed79-f303-4d12-a1f5-4203fc0ddde7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "newton_backtracking (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnekAseLCVy8"
      },
      "source": [
        "## Questão 2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Considere a função de Rosenbrock"
      ],
      "metadata": {
        "id": "3xS6VTM-Bn0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "function rosenb(x)\n",
        "  a = 1.0\n",
        "  b = 10.0\n",
        "\n",
        "  f = (a - x[1])^2 + b*(x[2] - x[1]^2)^2\n",
        "\n",
        "  grad_f = [ -2*(a - x[1]) + 2*b*(x[2] - x[1]^2)*(-2*x[1]),\n",
        "        2*b*(x[2] - x[1]^2)]\n",
        "\n",
        "  hess_f = [\n",
        "        2 - 4*b*(x[2] - x[1]^2) + 8*b*x[1]^2   -4*b*x[1];\n",
        "        -4*b*x[1]                               2*b\n",
        "  ]\n",
        "\n",
        "  return f, grad_f, hess_f\n",
        "end"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clYbT8rbBw1D",
        "outputId": "a72422f4-034b-42d1-ec2f-6f3a23aae6fb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "rosenb (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparemos ambos os métodos anteriores considerando os pontos iniciais $x_0 = (1.01, 1.01)$ e $x_1 = (-1.0, 1.2)$"
      ],
      "metadata": {
        "id": "Mx_AfghMCt4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x0 = [1.01, 1.01]\n",
        "\n",
        "x, max_iter_sd, gnorm_sd = steepest_descent_backtracking(rosenb, x0)\n",
        "@printf(\"Gradiente:\\n  Número de iterações: %d\\n  Gradiente final: %.6e\\n  Ponto final: [%.6f, %.6f]\\n\\n\",\n",
        "        max_iter_sd, gnorm_sd, x[1], x[2])\n",
        "\n",
        "x, max_iter_n, gnorm_n = newton_backtracking(rosenb, x0)\n",
        "@printf(\"Newton:\\n  Número de iterações: %d\\n  Gradiente final (norma): %.6e\\n  Ponto final: [%.6f, %.6f]\\n\\n\",\n",
        "        max_iter_n, gnorm_n, x[1], x[2])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "em0_EC6vDKNG",
        "outputId": "f6a4a35b-1ff0-46f8-c86a-35181e6984a0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradiente:\n",
            "  Número de iterações: 1027\n",
            "  Gradiente final: 9.818612e-07\n",
            "  Ponto final: [1.000001, 1.000002]\n",
            "\n",
            "Newton:\n",
            "  Número de iterações: 3\n",
            "  Gradiente final (norma): 4.895830e-10\n",
            "  Ponto final: [1.000000, 1.000000]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = [-1.0, 1.2]\n",
        "\n",
        "x, max_iter_sd, gnorm_sd = steepest_descent_backtracking(rosenb, x1)\n",
        "@printf(\"Gradiente:\\n  Número de iterações: %d\\n  Gradiente final: %.6e\\n  Ponto final: [%.6f, %.6f]\\n\\n\",\n",
        "        max_iter_sd, gnorm_sd, x[1], x[2])\n",
        "\n",
        "x, max_iter_n, gnorm_n = newton_backtracking(rosenb, x1, max_iter=5000)\n",
        "@printf(\"Newton:\\n  Número de iterações: %d\\n  Gradiente final (norma): %.6e\\n  Ponto final: [%.6f, %.6f]\\n\\n\",\n",
        "        max_iter_n, gnorm_n, x[1], x[2]) # VER ISSO DAQUI"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ek9SUpKDS6I",
        "outputId": "6552b011-ceba-46d2-8351-9f1e7bd7ba7d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradiente:\n",
            "  Número de iterações: 1184\n",
            "  Gradiente final: 9.714477e-07\n",
            "  Ponto final: [0.999999, 0.999998]\n",
            "\n",
            "Newton:\n",
            "  Número de iterações: 5000\n",
            "  Gradiente final (norma): 5.656854e+00\n",
            "  Ponto final: [-1.000000, 1.200000]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para $x_0 = (1.01, 1.01)$ próximo do mínimo $x^* = (1,1)$, o método de Newton converge quadraticamente, resultando em apenas 3 iterações, enquanto o método do gradiente precisou de 1027 iterações. Além disso, o método de Newton foi bem mais preciso quando comparado ao método do gradiente.\n",
        "\n",
        "Para $x_1 = (-1.0, 1.2)$, mais distante, o Newton falha em convergir (5000 iterações) porque $H(x)$ longe do mínimo pode não ser positiva definida, enquanto o gradiente ainda converge (1184 iterações), mas de forma linear, ilustrando que a convergência quadrática de Newton é local.\n",
        "\n",
        "Observe que, para a função de Rosenbrock\n",
        "\n",
        "$$\n",
        "  f(x_1, x_2) = (x_1 - 1)^2 + 10 (x_2 - x_1^2)^2,\n",
        "$$\n",
        "\n",
        "a Hessiana é\n",
        "\n",
        "$$\n",
        "  H(x) =\n",
        "  \\begin{bmatrix}\n",
        "  2 - 40(x_2 - x_1^2) + 80 x_1^2 & -40 x_1 \\\\\n",
        "  -40 x_1 & 20\n",
        "  \\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "e o determinante é\n",
        "\n",
        "$$\n",
        "  \\det(H) = 40 - 800(x_2 - x_1^2).\n",
        "$$\n",
        "\n",
        "Para o ponto inicial $x_1 = (-1, 1.2)$:\n",
        "\n",
        "$$\n",
        "  x_2 - x_1^2 = 1.2 - 1 = 0.2 \\implies \\det(H) < 0,\n",
        "$$\n",
        "\n",
        "ou seja, a Hessiana **não é positiva definida** nesse ponto. Isso explica por que o método de Newton não converge a partir desse ponto inicial.\n"
      ],
      "metadata": {
        "id": "_31aotrtRis2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzBgumq1CYA2"
      },
      "source": [
        "## Questão 3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "function exact_line_search_quadratic(A, b, x, d)\n",
        "  numerator = dot(b, d) - dot(d, A * x)\n",
        "  denominator = dot(d, A * d)\n",
        "\n",
        "  if denominator <= 0 || abs(denominator) < 1e-14\n",
        "    return 1e-6   # passo mínimo seguro\n",
        "  end\n",
        "  return numerator / denominator\n",
        "end"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAFJt8bFrv1U",
        "outputId": "8d094eda-3fce-40b5-9e73-000c0004aca1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "exact_line_search_quadratic (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "function quadratic(x, A, b)\n",
        "  f = 0.5 * dot(x, A * x) - dot(b, x)\n",
        "  g = A * x - b\n",
        "  H = A\n",
        "  return f, g, H\n",
        "end"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryacwBarqdTh",
        "outputId": "a841057d-77d8-42b5-ecde-ad3a9bb25f15"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "quadratic (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "function householder_matrix(n)\n",
        "  u = randn(n)\n",
        "  u /= norm(u)\n",
        "  U = Matrix(I, n, n) - 2.0 * (u * u')\n",
        "  return U\n",
        "end"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usNTyzyP0OEg",
        "outputId": "2ba10d0c-065e-41df-cee7-08d179691785"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "householder_matrix (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gradiente com busca linear exata**"
      ],
      "metadata": {
        "id": "hkm5yTJVhOv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "function steepest_descent_exact(A, b, x0; max_iter=2000, tol=1e-6)\n",
        "  x = copy(x0)\n",
        "\n",
        "  for k = 0:max_iter-1\n",
        "    f, g, _ = quadratic(x, A, b)\n",
        "\n",
        "    gnorm = norm(g)\n",
        "    if gnorm <= tol\n",
        "      return x, k, gnorm\n",
        "    end\n",
        "\n",
        "    d = -g\n",
        "\n",
        "    # Busca linear exata (fixar direção, determinar tamanho de passo)\n",
        "    alpha = exact_line_search_quadratic(A, b, x, d)\n",
        "\n",
        "    x = x + alpha * d\n",
        "  end\n",
        "\n",
        "  f, g, _ = quadratic(x, A, b)\n",
        "  gnorm = norm(g)\n",
        "  return x, max_iter, gnorm\n",
        "end"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSWeM9ScsFPN",
        "outputId": "2dbc2545-1433-4cee-e68e-223e6d94ce72"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "steepest_descent_exact (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Newton com busca linear exata**"
      ],
      "metadata": {
        "id": "vV_BWIVFhRvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "function newton_exact(A, b, x0; max_iter=2000, tol=1e-6)\n",
        "  x = copy(x0)\n",
        "\n",
        "  for k = 0:max_iter-1\n",
        "    f, g, H = quadratic(x, A, b)\n",
        "\n",
        "    gnorm = norm(g)\n",
        "    if gnorm <= tol\n",
        "      return x, k, gnorm\n",
        "    end\n",
        "\n",
        "    # direção de Newton\n",
        "    p = - H \\ g\n",
        "\n",
        "    # passo exato\n",
        "    alpha = exact_line_search_quadratic(A, b, x, p)\n",
        "\n",
        "    x = x + alpha * p\n",
        "  end\n",
        "\n",
        "  f, g, H = quadratic(x, A, b)\n",
        "  return x, max_iter, norm(g)\n",
        "end"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLL9JItHMYah",
        "outputId": "7b9cb092-eb3b-48c9-a5bb-c053fcad0ebc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "newton_exact (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cria uma instância quadrática $f(x) = \\tfrac{1}{2} x^T A x - b^T x$ de dimensão $n$ com uma distribuição específica de autovalores:  \n",
        "- `:equal`: todos os autovalores iguais (bem condicionada).  \n",
        "- `:two`: apenas dois valores diferentes (condicionamento moderado).  \n",
        "- `:spread`: autovalores variados de 1 até 1000 (mal condicionada)."
      ],
      "metadata": {
        "id": "s1Xx8LPVhsb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "function generate_quadratic_instance(n, case)\n",
        "  U = householder_matrix(n)\n",
        "\n",
        "  eigenvalues = zeros(n)\n",
        "\n",
        "  if case == :equal\n",
        "    eigenvalues .= 1.0\n",
        "  elseif case == :two\n",
        "    eigenvalues[1:div(n,2)] .= 2.0\n",
        "    eigenvalues[div(n,2)+1:end] .= 5.0\n",
        "    shuffle!(eigenvalues)\n",
        "  elseif case == :spread\n",
        "    eigenvalues .= collect(LinRange(1.0, 1000.0, n))\n",
        "    shuffle!(eigenvalues)\n",
        "  else\n",
        "    error(\"unkown case\")\n",
        "  end\n",
        "\n",
        "  Lambda = Diagonal(eigenvalues)\n",
        "  A = U * Lambda * U'\n",
        "  A = 0.5 * (A + A')   # garante simetria\n",
        "\n",
        "  b = randn(n) # mudar, pode usar vetor b igual a 0\n",
        "  x0 = randn(n) # mudar, pode usar x0 (diferente de 0), talvez vetor igual a 1\n",
        "\n",
        "  return A, b, x0, eigenvalues\n",
        "end"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6aRxP-0yTMk",
        "outputId": "eef36fe7-db3f-4a98-f9b9-9ead273d8c89"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "generate_quadratic_instance (generic function with 1 method)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neste bloco, aplicamos os métodos de otimização (`steepest_descent_exact` e `newton_exact`) em várias instâncias quadráticas geradas:\n",
        "\n",
        "- `dimensions = [10, 100, 1000]`: diferentes tamanhos da matriz $A$.  \n",
        "- `cases = [:equal, :two, :spread]`: diferentes distribuições de autovalores para testar o condicionamento.\n"
      ],
      "metadata": {
        "id": "yYN8ENPaiIut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dimensions = [10, 100, 1000]\n",
        "cases = [:equal, :two, :spread]\n",
        "\n",
        "for n in dimensions, case in cases\n",
        "    A, b, x0, eigenvalues = generate_quadratic_instance(n, case)\n",
        "\n",
        "    # Gradiente\n",
        "    t_sd = @elapsed x_sd, k_sd, gnorm_sd = steepest_descent_exact(A, b, x0, max_iter=10000)\n",
        "\n",
        "    # Newton\n",
        "    t_newt = @elapsed x_newt, k_newt, gnorm_newt = newton_exact(A, b, x0, max_iter=10000)\n",
        "\n",
        "    println(\"Dimensão: $n, Caso: $case\")\n",
        "    println(\"  Gradiente:\")\n",
        "    println(\"    Iterações: $k_sd\")\n",
        "    println(\"    Tempo: $(round(t_sd, digits=4)) s\")\n",
        "    println(\"  Newton:\")\n",
        "    println(\"    Iterações: $k_newt\")\n",
        "    println(\"    Tempo: $(round(t_newt, digits=4)) s\\n\")\n",
        "end\n",
        "\n",
        "## ADICIONAR AVALIAÇÃO DE FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CYt3iuHMbHo",
        "outputId": "2fbb5f47-a11f-41a6-c29e-a124b6013910"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensão: 10, Caso: equal\n",
            "  Gradiente:\n",
            "    Iterações: 1\n",
            "    Tempo: 0.5898 s\n",
            "  Newton:\n",
            "    Iterações: 1\n",
            "    Tempo: 0.185 s\n",
            "\n",
            "Dimensão: 10, Caso: two\n",
            "  Gradiente:\n",
            "    Iterações: 11\n",
            "    Tempo: 0.0 s\n",
            "  Newton:\n",
            "    Iterações: 1\n",
            "    Tempo: 0.0 s\n",
            "\n",
            "Dimensão: 10, Caso: spread\n",
            "  Gradiente:\n",
            "    Iterações: 6873\n",
            "    Tempo: 0.008 s\n",
            "  Newton:\n",
            "    Iterações: 1\n",
            "    Tempo: 0.0 s\n",
            "\n",
            "Dimensão: 100, Caso: equal\n",
            "  Gradiente:\n",
            "    Iterações: 1\n",
            "    Tempo: 0.0 s\n",
            "  Newton:\n",
            "    Iterações: 1\n",
            "    Tempo: 0.0002 s\n",
            "\n",
            "Dimensão: 100, Caso: two\n",
            "  Gradiente:\n",
            "    Iterações: 15\n",
            "    Tempo: 0.0001 s\n",
            "  Newton:\n",
            "    Iterações: 1\n",
            "    Tempo: 0.0002 s\n",
            "\n",
            "Dimensão: 100, Caso: spread\n",
            "  Gradiente:\n",
            "    Iterações: 6579\n",
            "    Tempo: 0.0676 s\n",
            "  Newton:\n",
            "    Iterações: 1\n",
            "    Tempo: 0.0002 s\n",
            "\n",
            "Dimensão: 1000, Caso: equal\n",
            "  Gradiente:\n",
            "    Iterações: 1\n",
            "    Tempo: 0.0029 s\n",
            "  Newton:\n",
            "    Iterações: 1\n",
            "    Tempo: 0.0477 s\n",
            "\n",
            "Dimensão: 1000, Caso: two\n",
            "  Gradiente:\n",
            "    Iterações: 17\n",
            "    Tempo: 0.0246 s\n",
            "  Newton:\n",
            "    Iterações: 1\n",
            "    Tempo: 0.058 s\n",
            "\n",
            "Dimensão: 1000, Caso: spread\n",
            "  Gradiente:\n",
            "    Iterações: 7453\n",
            "    Tempo: 9.1204 s\n",
            "  Newton:\n",
            "    Iterações: 1\n",
            "    Tempo: 0.0571 s\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observa-se que o método de Newton converge em apenas uma iteração para todos os casos testados, independentemente da dimensão da matriz ou da distribuição dos autovalores. Isso ocorre porque, para uma função quadrática, a direção de Newton aponta exatamente para o mínimo, e o passo exato leva diretamente a ele. O tempo de execução aumenta levemente com a dimensão devido à necessidade de resolver o sistema linear $H p = g$, mas permanece extremamente baixo.\n",
        "\n",
        "Por outro lado, o desempenho do método do gradiente dependente do condicionamento da matriz $A$. Nos casos de autovalores iguais ou com apenas dois distintos, o número de iterações necessárias é relativamente baixo. Entretanto, quando os autovalores estão muito espalhados, o método precisa de mais iterações para convergir. O tempo de processamento cresce significativamente à medida que a dimensão da matriz aumenta."
      ],
      "metadata": {
        "id": "zn1JgXKCjth3"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Julia",
      "name": "julia"
    },
    "language_info": {
      "name": "julia"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}